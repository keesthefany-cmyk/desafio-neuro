# ü§ñ **Neurotech Onboarding System ‚Äî IA Multiagente para Onboarding Automatizado**

## üéØ Vis√£o Geral

Sistema inteligente de **onboarding automatizado** para novos funcion√°rios utilizando:

- **IA Multiagente com AutoGen** (GraphFlow coordenado)
- **Coleta autom√°tica de 8 campos obrigat√≥rios**
- **Armazenamento autom√°tico de dados ao completar** (sem a√ß√µes manuais)
- **Busca inteligente com Elasticsearch (RAG)**
- **FastAPI como gateway HTTP**
- **Redis como fila de mensagens e gerenciamento de estado**
- **Infraestrutura Docker Compose**
- **Deduplica√ß√£o de mensagens multi-layer** (user, coordinator, talker)

A solu√ß√£o automatiza completamente o fluxo de onboarding, coletando dados conversacionalmente e armazenando quando todos os 8 campos forem preenchidos.

---

# üèóÔ∏è Arquitetura do Sistema

## üìä Diagrama de Fluxo

```
Usu√°rio (WhatsApp)
    ‚Üì
POST /api/onboarding/message
    ‚Üì
FastAPI ‚Üí Input Buffer (Redis)
    ‚Üì
QueueManager (income_messages)
    ‚Üì
AiOrchestrator.execute()
    ‚îú‚Üí User Message Processing (deduplicated)
    ‚îú‚Üí Coordinator Agent (single execution per run)
    ‚îú‚Üí Talker Agent (single response per run)
    ‚îî‚Üí Auto-store if complete (8 fields)
    ‚Üì
Output Queue (Redis) ‚Üí WhatsApp
```

## ü§ñ Tr√™s Agentes Coordenados (GraphFlow)

### 1Ô∏è‚É£ **Coordinator Agent**
- Gerencia o fluxo de coleta de dados
- Solicita campos um por um (conversacional)
- Passa controle para o Talker enviar resposta
- Executa exatamente 1 vez por rodada (deduplicado)

### 2Ô∏è‚É£ **Talker Agent**
- Envia as mensagens ao usu√°rio final
- Formata respostas com linguagem amig√°vel
- Aguarda o Coordinator autorizar
- Gera exatamente 1 resposta por rodada (deduplicado com hash)

### 3Ô∏è‚É£ **Finalizer Agent** (opcional, n√£o ativo no fluxo atual)
- Encerrar processos
- Gerar confirma√ß√µes finais

---

# üìã Fluxo de Coleta de Dados

O sistema coleta **8 campos obrigat√≥rios** em ordem fixa:

| Campo | Tipo | Exemplo |
|-------|------|---------|
| 1Ô∏è‚É£ **Nome Completo** | texto | "Jo√£o Silva Santos" |
| 2Ô∏è‚É£ **CPF** | CPF | "123.456.789-00" |
| 3Ô∏è‚É£ **Data de Nascimento** | data | "15/03/1990" |
| 4Ô∏è‚É£ **Cargo** | texto | "Desenvolvedor Python" |
| 5Ô∏è‚É£ **Email Corporativo** | email | "joao.silva@neurotech.com" |
| 6Ô∏è‚É£ **Banco** | texto | "Banco do Brasil" |
| 7Ô∏è‚É£ **Ag√™ncia** | n√∫mero | "1234-5" |
| 8Ô∏è‚É£ **Conta Banc√°ria** | n√∫mero | "987654-3" |

### ‚öôÔ∏è Comportamento Autom√°tico

1. **Coleta conversacional**: Coordinator solicita 1 campo por vez
2. **Extra√ß√£o autom√°tica**: Sistema extrai valor da mensagem do usu√°rio
3. **Incremento**: Avan√ßa para pr√≥ximo campo
4. **Detec√ß√£o de completude**: Quando 8 campos ‚â• preenchidos
5. **Armazenamento autom√°tico**: Chama `store_employee_data()` automaticamente via tool

**Nenhuma a√ß√£o manual necess√°ria** ‚Äî tudo √© autom√°tico ao atingir 8 campos!

---

# üíª Tecnologias Utilizadas

| Tecnologia | Vers√£o | Prop√≥sito |
|-----------|--------|----------|
| **AutoGen** | 0.4.9 | Orquestra√ß√£o multiagente + GraphFlow |
| **FastAPI** | 0.104.0+ | HTTP API e webhooks |
| **Redis** | 7 (Alpine) | Filas de mensagens e estado |
| **Elasticsearch** | 8.11.0 | Base de conhecimento (RAG) |
| **OpenAI** | 1.30.0+ | Modelo GPT-4o-mini (temp=0.2) |
| **Pydantic** | 2.0.0+ | Valida√ß√£o de dados |
| **HTTPX** | 0.25.0+ | Requisi√ß√µes ass√≠ncronas |
| **Python** | 3.11+ | Ambiente de execu√ß√£o |

---

# üí¨ Fluxo da Conversa√ß√£o

Usu√°rio ‚Üí WhatsApp ‚Üí Webhook ‚Üí API FastAPI  
‚Üì  
ConversationManager  
‚Üì  
Redis Queue  
‚Üì  
Coordinator Agent  
‚Üì  
(Talker, Tools, Finalizer)  
‚Üì  
Resposta  
‚Üì  
WhatsApp do usu√°rio

---

# üöÄ Instala√ß√£o e Execu√ß√£o

## üìã Pr√©-requisitos

- Docker & Docker Compose instalados
- Python 3.11+ (para rodar localmente sem Docker)
- Vari√°veis de ambiente configuradas

## 1Ô∏è‚É£ Clonar e Configurar

```bash
git clone https://github.com/keesthefany-cmyk/desafio-neuro.git
cd desafio-neuro
```

## 2Ô∏è‚É£ Criar arquivo `.env`

```bash
cat > .env << EOF
# OpenAI
OPENAI_API_KEY=sk-proj-xxxxx

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_URL=redis://redis:6379/0

# Elasticsearch
ES_HOST=http://elasticsearch:9200
ES_PORT=9200

# API
PORT=8000
HOST=0.0.0.0

# Logging
LOG_LEVEL=DEBUG
EOF
```

## 3Ô∏è‚É£ Iniciar com Docker Compose

```bash
docker compose up -d --build
```

### üì° Servi√ßos Dispon√≠veis

| Servi√ßo | URL/Porta | Status |
|---------|-----------|--------|
| **API Onboarding** | `http://localhost:8000` | POST `/api/onboarding/message` |
| **Redis** | `localhost:6379` | Cache + Filas |
| **Elasticsearch** | `http://localhost:9200` | RAG + Busca |
| **Health Check** | `GET /api/health/openai` | Teste OpenAI |

---

## ‚ñ∂Ô∏è Usar Localmente (sem Docker)

```bash
# 1. Criar ambiente virtual
python3.11 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou: venv\Scripts\activate (Windows)

# 2. Instalar depend√™ncias
pip install -r requirements.txt

# 3. Configurar Redis (via docker ou local)
redis-server

# 4. Rodar a API
python main.py
```

A API estar√° em `http://localhost:8000`

---

# üîå Endpoints da API

## POST `/api/onboarding/message`

Envia uma mensagem para o sistema de onboarding.

**Request:**
```json
{
  "chat_key": "session-123",
  "user_type": "funcionario",
  "phone": "5581999999999",
  "message": "Jo√£o Silva"
}
```

**Response:**
```json
{
  "status": "success",
  "chat_key": "session-123",
  "message": "Qual seu CPF?"
}
```

## GET `/api/health/openai`

Testa conex√£o com OpenAI.

**Response:**
```json
{
  "status": "openai_api_ready",
  "model": "gpt-4o-mini",
  "connection": "ok"
}
```

---

# üìÅ Estrutura do Projeto

```
desafio-neuro/
‚îú‚îÄ‚îÄ main.py                          # Entrada FastAPI
‚îú‚îÄ‚îÄ tasks.py                         # Loop de resposta async
‚îú‚îÄ‚îÄ requirements.txt                 # Depend√™ncias
‚îú‚îÄ‚îÄ docker-compose.yml               # Orquestra√ß√£o
‚îú‚îÄ‚îÄ Dockerfile                       # Build da API
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ agents/                      # Agentes AutoGen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_builder.py        # Construtor de agentes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_factory.py        # Factory de cria√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user_proxy_agent.py     # Agente proxy do usu√°rio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent_config.py         # Configura√ß√µes
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                    # Servi√ßos core
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai_orchestrator.py      # Orquestrador principal (CRITICAL)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queue_manager.py        # Redis + filas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation_manager.py # Hist√≥rico de chat
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ message_processor.py    # Parsing de mensagens
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator_registry.py # Cache de orquestradores
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                       # Ferramentas dos agentes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools.py                # store_employee_data, search_kb, etc
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ configs/                     # Configura√ß√µes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Constantes e paths
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging_config.py       # Setup de logs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ templates/                   # Prompts e rules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.yaml            # Instru√ß√µes dos agentes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules.yaml              # Regras de neg√≥cio
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                        # Dados est√°ticos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neurotech.json          # Base de conhecimento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ politicas.json          # Pol√≠ticas da empresa
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ model/                       # Modelos Pydantic
‚îÇ       ‚îî‚îÄ‚îÄ requests/
‚îÇ           ‚îî‚îÄ‚îÄ remote_user_message.py
‚îÇ
‚îú‚îÄ‚îÄ data/                            # Dados de produ√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ employees/                   # Dados de funcion√°rios
‚îÇ   ‚îî‚îÄ‚îÄ (MongoDB ser√° aqui se usado)
‚îÇ
‚îî‚îÄ‚îÄ logs/                            # Arquivos de log
```

---

# üîë Componentes Cr√≠ticos

## `AiOrchestrator` (app/services/ai_orchestrator.py)

**Responsabilidade**: Orquestra todo o fluxo de IA

### M√©todos principais:

- `prepare()`: Inicializa agentes e GraphFlow uma √∫nica vez
- `execute(message)`: Executa GraphFlow com mensagem do usu√°rio
- `_run_graph_flow_stream()`: Loop de execu√ß√£o com deduplica√ß√£o multi-layer
  - `user_message_processed`: Flag para processar user message 1x
  - `coordinator_executed`: Flag para executar coordinator 1x
  - `processed_talker_messages`: Hash set para talker 1x
- `_update_collected_data_from_message()`: Extrai dados conversacionalmente
- `_is_collection_complete()`: Detecta quando 8 campos ‚â• preenchidos
- `_store_collected_data()`: Chama tool para armazenar automaticamente

## `QueueManager` (app/services/queue_manager.py)

Gerencia todas as opera√ß√µes Redis:
- `income_messages`: Fila de entrada
- `outcome_queue`: Fila de sa√≠da global
- Chat state tracking (waiting_user_response, accumulating_first_interaction)

## `ConversationManager` (app/services/conversation_manager.py)

Persiste hist√≥rico de conversa e detecta finaliza√ß√µes.

---

# üéØ Fluxo Detalhado: Do Usu√°rio ao Armazenamento

```
1. Usu√°rio envia mensagem no WhatsApp
   ‚îî‚îÄ> POST /api/onboarding/message

2. FastAPI valida e enfileira
   ‚îî‚îÄ> input_buffer (Redis)

3. QueueManager processa
   ‚îî‚îÄ> income_messages (formatado com metadata)

4. AiOrchestrator.execute() √© chamado
   ‚îî‚îÄ> Prepara GraphFlow se primeira vez
   ‚îî‚îÄ> Extrai user message (1x)
   ‚îî‚îÄ> Coordinator gera instru√ß√£o (1x)
   ‚îî‚îÄ> Talker formata resposta (1x)
   ‚îî‚îÄ> Sistema detecta 8 campos coletados?
       ‚îî‚îÄ> SIM: Chama store_employee_data()
       ‚îî‚îÄ> N√ÉO: Continua aguardando pr√≥ximo campo

5. Resposta √© enfileirada globalmente
   ‚îî‚îÄ> outcome_queue (Redis)

6. tasks.py (reply_loop) consome
   ‚îî‚îÄ> Envia para WhatsApp do usu√°rio

7. Repetir at√© onboarding completo
```

---

# üß™ Testando o Sistema

## Teste r√°pido via curl

```bash
curl -X POST http://localhost:8000/api/onboarding/message \
  -H "Content-Type: application/json" \
  -d '{
    "chat_key": "test-session",
    "user_type": "funcionario",
    "phone": "5581999999999",
    "message": "Jo√£o Silva"
  }'
```

## Teste via script Python

```bash
python test_onboarding_flow.py
```

## Ver logs em tempo real

```bash
docker compose logs -f onboarding-api
```

Procure por:
- ‚úÖ `[chat:session-xxx] Campo atualizado` ‚Äî Campo coletado
- ‚úÖ `Todos os 8 campos coletados!` ‚Äî Pronto para armazenar
- ‚úÖ `store_employee_data chamado` ‚Äî Dados salvos

---

# üîç Monitoramento e Debugging

## Health Checks

```bash
# OpenAI
curl http://localhost:8000/api/health/openai

# MCP (se dispon√≠vel)
curl http://localhost:8000/api/health/mcp

# Redis
redis-cli ping  # PONG se online

# Elasticsearch
curl http://localhost:9200/_cluster/health
```

## Logs estruturados

Todos os logs est√£o em `/logs/` com timestamps e n√≠veis:

```
2025-12-11 00:49:22,465 [INFO] app.services.ai_orchestrator: [chat:session-123] Campo atualizado: Nome = Jo√£o Silva
2025-12-11 00:49:22,467 [DEBUG] app.services.ai_orchestrator: [chat:session-123] coordinator: {...}
```

## Chaves Redis relevantes

```bash
# Ver filas ativas
redis-cli KEYS "chat:*"

# Inspecionar income messages
redis-cli LRANGE "chat:session-123:income_messages" 0 -1

# Inspecionar estado
redis-cli GET "chat:session-123:status"
```

---

# ‚öôÔ∏è Configura√ß√£o Avan√ßada

## Modificar Prompts dos Agentes

Edite `app/templates/prompts.yaml`:

```yaml
coordinator_system_prompt: |
  Voc√™ √© um assistente especializado em onboarding...
  
talker_system_prompt: |
  Voc√™ √© respons√°vel por...
```

Mudan√ßas entram em efeito imediatamente no pr√≥ximo `execute()`.

## Adicionar Campos √† Coleta

1. Edite `_update_collected_data_from_message()` em `ai_orchestrator.py`
2. Atualize o mapeamento de campos
3. Aumente o limite de `_is_collection_complete()` de 8 para N

## Customizar Tool de Armazenamento

Edite `app/tools/tools.py` ‚Üí `store_employee_data_tool()`:

```python
async def store_employee_data_tool(user_id: str, status: str, data: dict):
    # Conectar com seu banco (MongoDB, PostgreSQL, etc)
    # Persistir dados
    pass
```

---

# üìä Entendendo a Deduplica√ß√£o Multi-Layer

O sistema previne **3 tipos de duplicatas** simultaneamente:

### 1. User Message Deduplication
**Problema**: GraphFlow pode passar user message m√∫ltiplas vezes no loop
**Solu√ß√£o**: `user_message_processed = False` ‚Üí marcado como `True` na primeira

### 2. Coordinator Deduplication
**Problema**: Coordinator pode executar > 1x no mesmo run
**Solu√ß√£o**: `coordinator_executed = False` ‚Üí `continue` se j√° executado

### 3. Talker Message Deduplication
**Problema**: Talker pode enviar mesma mensagem N vezes
**Solu√ß√£o**: Hash-based tracking com `processed_talker_messages` set

**Resultado**: Exatamente 1 mensagem do talker por execute()

---

# üêõ Troubleshooting

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| "Chat key not found" | Session expirou no Redis | Cache TTL muito curto em `queue_manager.py` |
| Talker envia 2 mensagens | Coordinator executou 2x (BUG ANTIGO) | ‚úÖ Corrigido com `coordinator_executed` flag |
| Campo n√£o coletado | Prompt do coordinator confuso | Edite prompts.yaml, simplifique instru√ß√µes |
| Armazenamento n√£o funciona | Tool n√£o implementada | Implemente `store_employee_data_tool()` em tools.py |
| Elasticsearch offline | Porta 9200 n√£o acess√≠vel | `docker compose ps` e verifique sa√∫de |
| Redis full | Limpeza de dados antigos faltando | `FLUSHDB` periodicamente ou TTL autom√°tico |

---

# üìù Contribuindo

1. Criar branch: `git checkout -b feature/sua-feature`
2. Commit: `git commit -am "Descri√ß√£o da mudan√ßa"`
3. Push: `git push origin feature/sua-feature`
4. Abrir Pull Request

### Padr√µes de c√≥digo
- Use type hints (`from typing import ...`)
- Logs via `logger.debug()`, `logger.info()`
- Async/await para I/O (Redis, OpenAI)
- Docstrings em fun√ß√µes cr√≠ticas

---

